{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a config with tokenizer and model from h-face for use in training and upload it to wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from tokenizer import build_tokenizer\n",
    "from transformers import AutoModelForCausalLM, GPTNeoXConfig\n",
    "from os import environ\n",
    "\n",
    "environ['WANDB_USERNAME']='pavel-tikhomirov'\n",
    "environ['WANDB_DIR']=f'/main/draft-v2/{environ[\"WANDB_USERNAME\"]}-runs/'\n",
    "environ['TOKENIZERS_PARALLELISM']='false'\n",
    "\n",
    "\n",
    "tokenizer = build_tokenizer('word-level', fdim=2, add_commutator_tokens=False,\n",
    "                            add_prompt_tokens=True, add_post_processor=True)\n",
    "\n",
    "\n",
    "from transformers import GPT2Config\n",
    "config = GPT2Config(\n",
    "    vocab_size = len(tokenizer.get_vocab()),\n",
    "    n_embd     = 768,\n",
    "    n_layer    = 8,\n",
    "    n_head     = 6,\n",
    "    n_inner    = 512,\n",
    "    \n",
    "    bos_token_id = tokenizer.bos_token_id,\n",
    "    eos_token_id = tokenizer.eos_token_id,\n",
    "    pad_token_id = tokenizer.pad_token_id,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.n_embd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d83327c98ebf45b3a149d86099ced0ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112213921215799, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/main/draft-v2/pavel-tikhomirov-runs/wandb/run-20240706_183451-ll20d498</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ml-in-algebraic-topology/whitehead/runs/ll20d498' target=\"_blank\">skilled-snow-141</a></strong> to <a href='https://wandb.ai/ml-in-algebraic-topology/whitehead' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ml-in-algebraic-topology/whitehead' target=\"_blank\">https://wandb.ai/ml-in-algebraic-topology/whitehead</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ml-in-algebraic-topology/whitehead/runs/ll20d498' target=\"_blank\">https://wandb.ai/ml-in-algebraic-topology/whitehead/runs/ll20d498</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/tmp/tmp2p65xo4a)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1e3b55cb97749559af9c49dabef8ebb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.014 MB of 0.020 MB uploaded\\r'), FloatProgress(value=0.7059475078256682, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "W&B sync reduced upload amount by 13.4%             "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">skilled-snow-141</strong> at: <a href='https://wandb.ai/ml-in-algebraic-topology/whitehead/runs/ll20d498' target=\"_blank\">https://wandb.ai/ml-in-algebraic-topology/whitehead/runs/ll20d498</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/main/draft-v2/pavel-tikhomirov-runs/wandb/run-20240706_183451-ll20d498/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "with TemporaryDirectory() as dir,\\\n",
    "     wandb.init(project = 'whitehead', entity = 'ml-in-algebraic-topology', job_type = 'build-model-config'):\n",
    "         \n",
    "    tokenizer.save_pretrained(dir)\n",
    "    config.save_pretrained(dir)\n",
    "\n",
    "    artifact = wandb.Artifact(name = 'gpt-2-fdim-2', type = 'model-config', metadata = {\n",
    "        'parameters': sum(p.numel() for p in model.parameters()),\n",
    "        **config.to_dict(),\n",
    "    }, description = \"GPT2 with `word-level` tokenizer with prompt tokens for $F\\langle x_1, x_2 \\rangle $. Add eos and bos. Whitehead testing\")\n",
    "\n",
    "    artifact.add_dir(dir)\n",
    "\n",
    "    wandb.run.log_artifact(artifact)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
